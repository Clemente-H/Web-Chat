{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent for Mixtral\n",
    "\n",
    "Multimodal Agent: Image Captioning with Mixtral 7B, togheter API  \n",
    "\n",
    "### tutorial\n",
    "https://medium.com/@shivansh.kaushik/multimodal-agent-image-captioning-with-mistral-7b-on-cpu-a82d35c84549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM\n",
    "\n",
    "Using langchain and together ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_together import Together\n",
    "llm = Together(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    top_k=1,\n",
    "    together_api_key=os.getenv(\"TOGETHER_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base structured-chat-agent prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needs to be moddified to work with our agents and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt[0].prompt.template = prompt[0].prompt.template[0:394] + \"```\\n\\n\\nFor example, if you want to use a tool to get an image's caption, your $JSON_BLOB might look like this:\\n\\n```\\n{{\\n    'action': 'image_captioner_json', \\n    'action_input': {{'query': 'images url'}}\\n}}```\" + prompt[0].prompt.template[394:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n```\\n\\n\\nFor example, if you want to use a tool to get an image\\'s caption, your $JSON_BLOB might look like this:\\n\\n```\\n{{\\n    \\'action\\': \\'image_captioner_json\\', \\n    \\'action_input\\': {{\\'query\\': \\'images url\\'}}\\n}}```Follow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image descriptor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# blip_processor = BlipProcessor.from_pretrained(\"kha-white/manga-ocr-base\")\n",
    "# blip_model = BlipForConditionalGeneration.from_pretrained(\"kha-white/manga-ocr-base\")\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Initation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "#from pydantic import BaseModel, Field\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "class ImageCaptionerInput(BaseModel):\n",
    "    image_url: str = Field(description=\"URL of the image that is to be described\")\n",
    "\n",
    "\n",
    "@tool(\"image_captioner\", return_direct=True, args_schema=ImageCaptionerInput)\n",
    "def image_captioner(image_url: str) -> str:\n",
    "    \"\"\"Provides information about the image\"\"\"\n",
    "    raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
    "    inputs = blip_processor(raw_image, return_tensors=\"pt\")\n",
    "    out = blip_model.generate(**inputs)\n",
    "    return blip_processor.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [image_captioner]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent, create_structured_chat_agent\n",
    "#agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to describe the image. I will use the image_captioner tool.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"image_captioner\",\n",
      "  \"action_input\": \"https://www.barcelo.com/guia-turismo/wp-content/uploads/2020/06/lago-di-como.jpg\"\n",
      "}\n",
      "```\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clemente/micromamba/envs/py311/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3ma lake with a boat in it\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Que hay en esta imagen https://www.barcelo.com/guia-turismo/wp-content/uploads/2020/06/lago-di-como.jpg',\n",
       " 'output': 'a lake with a boat in it'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Que hay en esta imagen https://www.barcelo.com/guia-turismo/wp-content/uploads/2020/06/lago-di-como.jpg\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
